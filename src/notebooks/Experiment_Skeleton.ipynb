{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, pathlib\n",
    "from scipy.stats import kendalltau\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciPy definiton of Kendall's Tau: \n",
    "### $$\\frac{P - Q}{\\sqrt{(P + Q + T) * (P + Q + U)}}$$\n",
    "#### where P is the number of concordant pairs, Q the number of discordant pairs, T the number of ties only in x, and U the number of ties only in y. If a tie occurs for the same pair in both x and y, it is not added to either T or U. (Note that ties will have been broken randomly by the calc_rank function below.) \n",
    "#### See https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.kendalltau.html for more information.\n",
    "#### Should we use non-negative definition of KT instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rank(seed, y):\n",
    "\n",
    "    '''\n",
    "    Function adapted from https://www.geeksforgeeks.org/rank-elements-array/\n",
    "    Randomly breaks ties using np random seed\n",
    "    \n",
    "    Copied from utils.stabililty_utils.py\n",
    "    '''\n",
    "\n",
    "    # Set random seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Initialize rank vector \n",
    "    R = [0 for i in range(len(y))] \n",
    "\n",
    "    # Create an auxiliary array of tuples \n",
    "    # Each tuple stores the data as well as its index in y \n",
    "    # T[][0] is the data and T[][1] is the index of data in y\n",
    "    T = [(y[i], i) for i in range(len(y))] \n",
    "    \n",
    "    # Sort T according to first element \n",
    "    T.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Loop through items in T\n",
    "    i=0\n",
    "    while i < len(y): \n",
    "\n",
    "        # Get number of elements with equal rank \n",
    "        j = i \n",
    "        while j < len(y) - 1 and T[j][0] == T[j + 1][0]: \n",
    "            j += 1\n",
    "        n = j - i + 1\n",
    "\n",
    "        # If there is no tie\n",
    "        if n==1:\n",
    "            \n",
    "            # Get ID of this element\n",
    "            idx = T[i][1] \n",
    "            \n",
    "            # Set rank\n",
    "            rank = i+1\n",
    "            \n",
    "            # Assign rank\n",
    "            R[idx] = rank \n",
    "            \n",
    "        # If there is a tie\n",
    "        if n>1: \n",
    "            \n",
    "            # Create array of ranks to be assigned\n",
    "            ranks = list(np.arange(i+1, i+1+n)) \n",
    "            \n",
    "            # Randomly shuffle the ranks\n",
    "            np.random.shuffle(ranks) \n",
    "            \n",
    "            # Create list of element IDs\n",
    "            ids = [T[i+x][1] for x in range(n)] \n",
    "            \n",
    "            # Assign rank to each element\n",
    "            for ind, idx in enumerate(ids):\n",
    "                R[idx] = ranks[ind] \n",
    "\n",
    "        # Increment i \n",
    "        i += n \n",
    "    \n",
    "    # return rank vector\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = pathlib.Path(os.getcwd()).parents[1] / 'out'\n",
    "\n",
    "s_samples = 200\n",
    "n_runs = 500\n",
    "\n",
    "# Highest seed not yet used in data gen\n",
    "seed = s_samples*((n_runs+1)*3+2)\n",
    "\n",
    "# Initialize arrays to hold Kendall's Tau distances\n",
    "noise_kts = np.zeros([s_samples, n_runs])\n",
    "counter_kts_xres = np.zeros([s_samples, 2])\n",
    "counter_kts_nonres = np.zeros([s_samples, 2])\n",
    "kts_xres_a0_a1 = np.zeros(s_samples)\n",
    "kts_nonres_a0_a1 = np.zeros(s_samples)\n",
    "\n",
    "# Loop through s_samples\n",
    "for s in range(1, s_samples+1):\n",
    "    \n",
    "    # Read in counterfactual data\n",
    "    counter = pd.read_csv(out_dir/'counterfactual_data'/'stability'/'default'/'counter_samp_{}.csv'.format(s))\n",
    "    \n",
    "    # Get list of counterfactual Y columns\n",
    "    counter_y_cols = [x for x in counter.columns if 'cf_y_' in x]\n",
    "    \n",
    "    # Calculate ranks for each counterfactual Y\n",
    "    for y in counter_y_cols:\n",
    "        counter['rank_'+y[5:]] = calc_rank(seed=seed, y=counter[y])\n",
    "        seed += 1\n",
    "    \n",
    "    # Read in noise distribution data\n",
    "    noise = pd.read_csv(out_dir/'synthetic_data'/'stability'/'default'/'rankings'/'observed_samp_{}.csv'.format(s))\n",
    "    \n",
    "    # Get original rank\n",
    "    orig_rank = noise['rank']\n",
    "    \n",
    "    # Get KT distances between original rank and each rank from noise distribution\n",
    "    # Average will give expected noise KT for this sample\n",
    "    for n in range(1, n_runs+1):\n",
    "        noise_kt, noise_p = kendalltau(orig_rank, noise['rank_{}'.format(n)])\n",
    "        noise_kts[s-1][n-1] = noise_kt\n",
    "    \n",
    "    # For each intervention, A<-0 and A<-1\n",
    "    for a in range(2):\n",
    "        try:\n",
    "            # Get KT distance between original rank and counterfactual Y with resolving X\n",
    "            counter_kts_nonres[s-1][a] = kendalltau(orig_rank, counter['rank_nonres_a{}'.format(a)])[0]\n",
    "            \n",
    "            # Get KT distance between original rank and counterfactual Y with non-resolving X\n",
    "            counter_kts_xres[s-1][a] = kendalltau(orig_rank, counter['rank_xres_a{}'.format(a)])[0]\n",
    "            \n",
    "        # Catch exception for A=a not present in original dataset\n",
    "        # A<-a intervention will not have been performed\n",
    "        except:\n",
    "            counter_kts_nonres[s-1][a] = np.nan\n",
    "            counter_kts_xres[s-1][a] = np.nan\n",
    "    \n",
    "    # Get KT distance between counterfactual ranks for intervention A<-0 and for intervention A<-1\n",
    "    try:\n",
    "        # Distance between ranks resulting from each intervention for non-resolving X\n",
    "        kts_nonres_a0_a1[s-1] = kendalltau(counter['rank_nonres_a0'], counter['rank_nonres_a1'])[0]   \n",
    "        \n",
    "        # Distance between ranks resulting from each intervention for resolving X\n",
    "        kts_xres_a0_a1[s-1] = kendalltau(counter['rank_xres_a0'], counter['rank_xres_a1'])[0]\n",
    "        \n",
    "    # Catch exception for only one value of A present in original dataset\n",
    "    # Only one intervention will have been performed\n",
    "    except:\n",
    "        kts_nonres_a0_a1[s-1] = np.nan\n",
    "        kts_xres_a0_a1[s-1] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get expected KT distance between original rank and rank from re-sampled noise\n",
    "# Expectation taken over n_runs of noise distribution\n",
    "# E[ KT(original rank, rank from re-sampled noise) ]\n",
    "# 1 value for each sample\n",
    "exp_kt_noise = np.mean(noise_kts, axis=1)\n",
    "\n",
    "# Get expected value of expected KT distance between original rank and rank from re-sampled noise\n",
    "# Iterated expectation: expectation first taken over n_runs of noise distribution, then over s_samples\n",
    "# E[ E[ KT(original rank, rank from re-sampled noise) ] ]\n",
    "# 1 value for entire experiment trial\n",
    "exp_exp_kt_noise = np.mean(exp_kt_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get expected KT distance between original rank and counterfactual Y with non-resolving X\n",
    "# For intervention A<-0\n",
    "# Expectation taken over s_samples\n",
    "# E[ KT(original rank, counterfactual rank with non-resolving X for A<-0) ]\n",
    "# 1 value for entire experiment trial\n",
    "exp_kt_counter_nonres_a0 = np.nanmean(counter_kts_nonres[:,0])\n",
    "\n",
    "# Get expected KT distance between original rank and counterfactual Y with non-resolving X\n",
    "# For intervention A<-1\n",
    "# Expectation taken over s_samples\n",
    "# E[ KT(original rank, counterfactual rank with non-resolving X for A<-1) ]\n",
    "# 1 value for entire experiment trial\n",
    "exp_kt_counter_nonres_a1 = np.nanmean(counter_kts_nonres[:,1])\n",
    "\n",
    "# Get expected KT distance between original rank and counterfactual Y with resolving X\n",
    "# For intervention A<-0\n",
    "# Expectation taken over s_samples\n",
    "# E[ KT(original rank, counterfactual rank with resolving X for A<-0) ]\n",
    "# 1 value for entire experiment trial\n",
    "exp_kt_counter_xres_a0 = np.nanmean(counter_kts_xres[:,0])\n",
    "\n",
    "# Get expected KT distance between original rank and counterfactual Y with resolving X\n",
    "# For intervention A<-1\n",
    "# Expectation taken over s_samples\n",
    "# E[ KT(original rank, counterfactual rank with resolving X for A<-1) ]\n",
    "# 1 value for entire experiment trial\n",
    "exp_kt_counter_xres_a1 = np.nanmean(counter_kts_xres[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{E}\\big[KT(\\text{original rank, counterfactual rank with }\\textbf{non-resolving X}\\text{ for }\\textbf{A$\\leftarrow$0}) - \\hat{E}[KT(\\text{original rank, rank from re-sampled noise})]\\big]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7380536251402918"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_kt_counter_nonres_a0 - exp_exp_kt_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{E}\\big[KT(\\text{original rank, counterfactual rank with }\\textbf{non-resolving X}\\text{ for }\\textbf{A$\\leftarrow$1}) - \\hat{E}[KT(\\text{original rank, rank from re-sampled noise})]\\big]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7400244444444444"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_kt_counter_nonres_a1 - exp_exp_kt_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{E}\\big[KT(\\text{original rank, counterfactual rank with }\\textbf{resolving X}\\text{ for }\\textbf{A$\\leftarrow$0}) - \\hat{E}[KT(\\text{original rank, rank from re-sampled noise})]\\big]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.756684377104377"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_kt_counter_xres_a0 - exp_exp_kt_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{E}\\big[KT(\\text{original rank, counterfactual rank with }\\textbf{resolving X}\\text{ for }\\textbf{A$\\leftarrow$1}) - \\hat{E}[KT(\\text{original rank, rank from re-sampled noise})]\\big]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7584688888888886"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_kt_counter_xres_a1 - exp_exp_kt_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{E}[KT(\\text{counterfactual rank with }\\textbf{non-resolving X}\\text{ for }\\textbf{A$\\leftarrow$0}), \\text{counterfactual rank with }\\textbf{non-resolving X}\\text{ for }\\textbf{A$\\leftarrow$1})]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_kt_nonres_a0_a1 = np.nanmean(kts_nonres_a0_a1)\n",
    "exp_kt_nonres_a0_a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{E}[KT(\\text{counterfactual rank with }\\textbf{resolving X}\\text{ for }\\textbf{A$\\leftarrow$0}), \\text{counterfactual rank with }\\textbf{resolving X}\\text{ for }\\textbf{A$\\leftarrow$1})]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_kt_xres_a0_a1 = np.nanmean(kts_xres_a0_a1)\n",
    "exp_kt_xres_a0_a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
